---
title: "Computing distances for high-throughput data"
author: "[Michael Love](http://mikelove.github.io)"
output: html_document
---

Here we will explore a number of issues involved in comparing samples
in high-throughput data, and in computing distances between
samples. The main issues I want to introduce are: 

* sequencing depth as a technical artifact
* "batch effects" that distort measurements

An ideal dataset for exploring these issues is a large dataset with
both technical and biological aspects recorded as metadata. It's hard
with few samples to discern what are technical differences, and what
is simply *biological variability* among the samples in a
condition. Note that proper data analysis requires that biological
aspects of experiments be randomized or blocked with respect to
technical aspects. Below we will show the number of significant
differences we find when we simply compare measurements across the
sequencing center in which the samples were processed.

Here we will work with the 
[GEUVADIS](http://www.geuvadis.org) project data, which contains 465
unique RNA-seq samples. The RNA was extracted from lymphoblastoid cell
line samples from 5 populations of the 1000 Genomes Project: the
CEPH (CEU), Finns (FIN), British (GBR), Toscani (TSI) and Yoruba
(YRI). The CEPH population consists of Utah residents with Northern
and Western European ancestry.

We start by downloading the summarized data from 
[recount2](https://jhubiostatistics.shinyapps.io/recount/) (this
downloads ~75 Mb). 

```{r message=FALSE}
library(SummarizedExperiment)
url <- "http://duffel.rail.bio/recount/ERP001942/rse_gene.Rdata"
file <- "geuvadis_recount2.rda"
if (!file.exists(file)) download.file(url, file)
load(file)
library(here)
source(here("bioc","my_scale_counts.R"))
rse <- my_scale_counts(rse_gene)
```

Now we read the GEUVADIS phenotypic data from a TSV file. This
contains additional data not present in `colData` of the
SummarizedExperiment. 

```{r}
library(readr)
pheno <- read_tsv(here("dist","geuvadis.tsv"))
df <- data.frame(pheno[,c("Run_s","Center_Name_s","population_s")])
df <- data.frame(lapply(df, factor))
colnames(df) <- c("run","center","population")
levels(df$center)
levels(df$center) <- c("CGR","CNAG","HZM","ICMB","LUMC","MPIMG","UG","UU")
head(df)
```

We have more rows in the TSV than samples in `rse`. And there appear
to be technical replicates, as there are 465 samples in GEUVADIS
according to the project website.

```{r}
nrow(df)
ncol(rse)
```

Here I make sure that all the samples in `rse` are present in `df`,
and then match up the data in `df` and add it to the `colData` of `rse`:

```{r}
all(colnames(rse) %in% df$run)
m <- match(colnames(rse), df$run)
rse$center <- df$center[m]
rse$population <- df$population[m]
```

# Sequencing depth as a technical artifact

The total number of counts per sample is a technical artifact, which
we need to control for before computing distances. Let's compute the
sum of each column, and then divide by 1 million (we can call this
"column sum per million"). This has a large range, from the sample
with the least counts to the sample with the most counts.

The number of counts (either *reads* or pairs of reads which are
referred to as *fragments*) is known as the sample's *sequencing
depth*. 

```{r}
cspm <- colSums(assay(rse))/1e6
range(cspm)
```

Here I pick two samples in the dataset, with low and with high
sequencing depth:

```{r}
idx <- order(cspm)[c(100,500)]
cspm[idx]
```

Let's compare the counts for these two samples by making a simple
scatter plot:

```{r fig.width=5, fig.height=5}
plot(assay(rse)[,idx])
```

Clearly, the log is useful here, as all the points are clustered near
the origin. It's also useful to make the points somewhat transparent
using `rgb` so we can see how they overlay. Finally we add a line that
indicates y=x.

```{r fig.width=5, fig.height=5}
plot(log10(assay(rse)[,idx] + 1), 
     cex=.5, col=rgb(0,0,0,.1), pch=20)
abline(0,1,col="red", lwd=3)
```

# MA plot

The problem with the scatterplot above is that, we really care about
the differences between these two samples, but those differences are
on a 45 degree angle. A common plot in genomics is to put the
difference itself on the y-axis (typical the difference in log-scale measurements,
so the *log fold change*). The x-axis can then be the average between
the two values, whether on the original or log scale. This is called
an "MA-plot" for *minus over average*, or a Bland-Altman plot. Note
that we can now directly see the extent of the differences between
these samples. And we can easily see the systematic technical factor
associated with higher sequencing depth in the second sample.

```{r}
x <- log2(assay(rse)[,idx[1]] + 1)
y <- log2(assay(rse)[,idx[2]] + 1)
plot(.5*(x + y), y - x,
     cex=.5, col=rgb(0,0,0,.1), pch=20)
abline(h=0, col="red", lwd=3)
```

Remember, if we were to calculate Euclidean distances between samples
on the log scale, we would be calculating the differences drawn below,
squaring and summing them. So we definitely want to center these
differences on the x-axis here, as we know the systematic difference
is due solely to sequencing depth.

While we're making this plot, also note the inflation of differences
on the left side of the plot. This increase in variance depending on
signal strength -- called 
[heteroskedasticity](https://en.wikipedia.org/wiki/Heteroscedasticity)
in statistics -- is a technical artifact from the inherent count-based
measurements of high-throughput sequencing data, and needs to be dealt
with to compute biologically meaningful distances between samples.

```{r}
plot(.5*(x + y), y - x, type="h")
```

# Principle component analysis

As this is a graduate course in biostatistics, I'm assuming some
familiarity with 
[principle component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis). 
PCA is an invaluable technique for high-throughput data, to capture in
a 2D plot the inter-relationships between samples in the dataset. Note
that multidimensional scaling (MDS) on a Euclidean distance matrix
produces an equivalent plot as PCA. 

Performing PCA on unnormalized counts will allow us to see the extent
to which sequencing depth contributes to total variance (of
log-transformed counts).  Computing PCA on such a large matrix ~58,000
x ~660 takes a long time, so we subset to the top 20,000 genes by
unsupervised variance (taking the variance of each row of the matrix,
ignoring the technical and biological covariates).

We can notice two things from plotting PC1 over the column sums we
previously calculated: There is a single sample which is an outlier in
PC1, and otherwise, PC1 is capturing the differences between samples
in sequencing depth.

```{r}
library(matrixStats)
log.cts <- log(assay(rse) + 1)
rv <- rowVars(log.cts)
o <- order(rv,decreasing=TRUE)
system.time({
  pc <- prcomp(t(log.cts[head(o,20000),]))
}) # takes ~1 min
plot(cspm, pc$x[,1])
outlier <- which(pc$x[,1] > 300)
points(cspm[outlier], pc$x[outlier,1], col="blue", cex=3)
```

By plotting 20 "normal" samples and the outlier sample identified
above, we see that this sample has a very different distribution of
log counts. Remember from the above plot, the outlier does not have
the highest sequencing depth (as measured by total count).

```{r}
idx <- order(cspm)[round(seq(from=1,to=length(cspm),length=20))]
boxplot(log.cts[,c(idx,outlier)], range=0)
```

Here, we recompute the PCA, removing the outlier. Where we can clearly
see that PC1 is capturing sequencing depth, so we definitely want to
remove this technical effect.

```{r}
system.time({
  pc <- prcomp(t(log.cts[head(o,20000),-outlier]))
}) # takes ~1 min
plot(cspm[-outlier], pc$x[,1])
```

# Normalization for sequencing depth

We will discuss in class the reasons that the column sum is a bad
estimator for a sequencing depth correction. Briefly, it is because
the column sum is overly influenced by the genes with the very largest
counts, whereas we are interested in determining the shift on the log
scale that occurs across the entire range of counts. Most methods for
computing sequencing depth, or equivalently, *library size* correction
factors involve a robust estimator of the center of the log
ratios. Two of the most used methods are the median of ratios, used by
*DESeq* and *DESeq2* and the trimmed mean of log ratios, used by
*edgeR*. Here we will show how the median ratio method works for
RNA-seq counts. (Note that these normalization methods may work well
for some sequencing datasets, such as *bulk* RNA-seq, but not with
others, such as metagenomic data or single-cell RNA-seq. We will
discuss these additional kinds of datasets in class. 

We start by constructing a *pseudo-reference* sample, which will be
the geometric mean for each row. If a single sample has a 0, this
makes the geometric mean 0, and so this row will not be used for
calculating the correction factor. We can quickly compute the
geometric mean of each row using `log`, then `rowMean` then `exp`
(this is equivalent to the n-th root of the product of n terms).

Here I plot a single sample (the one with the highest column sum),
against this *pseudo-reference* sample, using the MA plot code I
showed before. The log ratios are shifted above the x-axis as
expected. 

```{r}
reference <- exp(rowMeans(log(assay(rse))))
x <- log2(reference)
y <- log2(assay(rse)[,which.max(cspm)] + 1)
plot(.5*(x + y), y - x,
     cex=.5, col=rgb(0,0,0,.2), pch=20)
abline(h=0, col="red", lwd=3)
```

Now we plot a histogram of the log ratios, and identify the median
with a vertical line (excluding those rows in which the geometric mean
was 0, and so the log was undefined).

```{r}
hist(y - x, breaks=200, col="grey", xlim=c(-2,5))
median.lfc <- median((y - x)[is.finite(x)])
abline(v = median.lfc, col="blue", lwd=3)
```

Now we draw the MA plot again, with the line through the median log
ratio calculated just now. The essential idea in the median ratio
method is to scale the raw counts down by this factor -- if we are
modeling with a GLM, to include this as an *offset* in the model.
Note that, it is not necessary that all points fall on the blue
line. We expect deviations representing within-condition biological
variation as well as differential expression across conditions. We
simply want to remove the systematic shift, which we know is a
technical artifact -- if there was a biological systematic shift in
expression levels for a sample, the experimenter needs to perform
additional controls or to identify "housekeeping" genes which they
believe do not change systematically. Finally, we note that we could
have applied something like the quantile normalization we showed
earlier in the exploration of microarray data. The scaling method is
typically preferred for count data, as we maintain information about
the precision of low vs high counts.

```{r}
plot(.5*(x + y), y - x,
     cex=.5, col=rgb(0,0,0,.2), pch=20)
abline(h=0, col="red", lwd=3)
abline(h=median.lfc, col="blue", lwd=3)
```

# What do we see after normalization

Instead of doing all this computation manually, we can use a
Bioconductor package *DESeq2* to do it for us. We will explore more
sophisticated transformations in the next section, but for now we will
just divide each column by a scaling factor, add 1 and take the
logarithm (base 2). The `plotPCA` automatically just looks at the top
genes by their unsupervised variance. We clearly see two groups
separating, and not by the center which prepared the sample.

```{r}
library(DESeq2)
dds <- DESeqDataSet(rse, ~1)
ntd <- normTransform(dds)
plotPCA(ntd, c("center"))
```

If we plot by the human population of the RNA-seq sample donors, we
see this explains PC1, but not PC2, where we see the clear separation.

```{r}
plotPCA(ntd, c("population"))
```

A reasonable guess is that PC2 represents the differences between the
sexes of the donors. We don't have this information in the metadata,
but we can make a rough guess of sex by summing up the counts of
genes expressed on the Y chromosome. 

**Note**: this is just a rough guess of the sex of the donors, for
demonstration of exploring this data. You wouldn't use such a method
for a final analysis. Another important note is that the Y chromosome
gene expression has nothing to do with the *gender* or
self-identification of the donors, and that binarizing a variable like
sex is an oversimplification. When talking about the sex
chromosomes, or biological sex, it is important to use the correct
term "sex" and not "gender".

We find out which `rowRanges` of the dataset are on `chrY`,
and then compute the sum of normalized counts from those genes:

```{r}
chrY <- as.logical(seqnames(rowRanges(ntd)) == "chrY")
dds <- estimateSizeFactors(dds)
chrYexprs <- colSums(counts(dds, normalized=TRUE)[chrY,])
hist(chrYexprs, breaks=100, col="grey")
```

It's a bit more clear on the log scale that there are two clusters: 

```{r}
hist(log10(chrYexprs), breaks=100, col="grey")
```

We make an estimate of sex by setting an arbitrary cut-point, and we
see that this roughly divides the groups of samples we saw as PC2:

```{r}
ntd$male <- log10(chrYexprs) > 3.5
plotPCA(ntd, intgroup="male")
```

We add our estimate of sex to the `colData` of the dataset, and save
this object, so we can continue working with this data later. The
saved version should be about 40 Mb.

```{r}
dds$male <- log10(chrYexprs) > 3.5
table(dds$male)
save(dds, file="geuvadis.rda")
```

Let's subset to just the female samples, and recalculate a PCA. We
don't see much clustering by the sequencing center overall:

```{r}
dds.f <- dds[,!dds$male]
ntd.f <- normTransform(dds.f)
plotPCA(ntd.f, c("center"))
```

But we can see clear clustering by the human populations:

```{r}
plotPCA(ntd.f, c("population"))
```

Finally, I note that, although we didn't see clustering by sequencing
center in the top two PCs above, there is still some technical
variation present in the normalized counts, associated with sequencing
center. For example, we can run F-tests on each row to find
association of log normalized counts with center. We then plot the log
normalized counts for the gene with the smallest p-value (uncorrected).

```{r message=FALSE}
library(genefilter)
tests <- rowFtests(assay(ntd.f), ntd.f$center)
top.gene.log.exprs <- assay(ntd.f)[which.min(tests$p.value),]
plot(top.gene.log.exprs ~ ntd.f$center)
```

You can see from a histogram of p-values over all genes, that there is
an enrichment of small p-values for certain genes. We will see in a
later section why the measurements for these genes show an association
with sequencing center.

```{r}
hist(tests$p.value, col="grey")
```
